{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Daniel Kadyrov\n",
    "\n",
    "Stevens ID: 10455680\n",
    "\n",
    "CS557 - Natural Language Processing\n",
    "\n",
    "Group 32 - Daniel Kadyrov"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Part 1\n",
    "Respond to J&M 2nd Exercises 3.10 and 3.11."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Exercise 3.10\n",
    "\n",
    "Add an option to your program to generate random sentences."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "\n",
    "corpus = brown.words(fileids=['ca16'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, Text, RegexpTokenizer\n",
    "\n",
    "# tokens = word_tokenize(\" \".join(corpus))\n",
    "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "tokens = tokenizer.tokenize(\" \".join(corpus)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<generator object ngram at 0x122d93970>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "def ngram(text, n):\n",
    "    for i in range(len(text)-n):\n",
    "        yield (text[i:i+n])\n",
    "\n",
    "ngrams = ngram(tokens, 3)\n",
    "ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'Columnist Walter Monroe Jr and it but more months before getting back to explain that she hadn t been addressed to Danny Thomas and there A Gift of masterful movie making'"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def markov_chain(ngrams, length): \n",
    "    word_dict = {}\n",
    "    for gram in ngrams:\n",
    "        if gram[0] in word_dict.keys(): \n",
    "            word_dict[gram[0]].append(gram[1])\n",
    "        else: \n",
    "            word_dict[gram[0]] = [gram[1]]\n",
    "\n",
    "    chain = [np.random.choice(tokens)]\n",
    "\n",
    "    for i in range(length):\n",
    "        chain.append(np.random.choice(word_dict[chain[-1]]))\n",
    "\n",
    "    chain = \" \".join(chain)\n",
    "\n",
    "    return chain\n",
    "\n",
    "text = markov_chain(ngrams, 30)\n",
    "text"
   ]
  },
  {
   "source": [
    "## 3.11\n",
    "\n",
    "Add an option to your program to compute the perplexity of a test set."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "55.63655037257783"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "from nltk.lm import MLE \n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "\n",
    "train, vocab = padded_everygram_pipeline(2, text)\n",
    "\n",
    "lm = MLE(2)\n",
    "lm.fit(train, vocab)\n",
    "lm.perplexity(text)"
   ]
  },
  {
   "source": [
    "# Part 2\n",
    "Find Python packages that apply Bayesian logic to classification and apply one to sentiment data. Such data can be downloaded from Amazon which collects reviews from customers, and possibly specialized rating sites for electronics, entertainment, restaurants, and other products and services. A sentiment data set using Amazon data is available with papers that report on research using it from here (Links to an external site.)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "with open(\"data/processed_stars/books/all_balanced.review\", \"r\") as file: \n",
    "    reviews = []\n",
    "    labels = []\n",
    "    for line in file: \n",
    "        review = []\n",
    "        liner = line.split(\" \")\n",
    "        for word in liner:\n",
    "            if \"#label#\" in word: \n",
    "                labels.append(int(float(word.split(\":\")[-1].split()[0])))\n",
    "            else: \n",
    "                review.append(word.split(\":\")[0]+\" \" * int(word.split(\":\")[1]))\n",
    "        reviews.append(\" \".join(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "reviews = np.asarray(reviews)\n",
    "labels = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, labels, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.5123546511627907"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "MNB = MultinomialNB()\n",
    "MNB.fit(X_train, Y_train)\n",
    "MNB.score(X_test, Y_test)\n"
   ]
  },
  {
   "source": [
    "# Part 3\n",
    "\n",
    "SentiWordNet can be used with Python and WordNet to sentitimentally classify a corpus because it assigns sentiment values, in positive, negative, and objectivity scores, to WordNet synsets. The following study, [\"Analyzing Movie Reviews - Sentiment Analysis I\"](https://www.kaggle.com/mgmarques/analyzing-movie-reviews-sentiment-analysis-i), available on Kaggle, follows using SentiWordNet for classification of movie reviews.\n",
    "\n",
    "The author goes through the reviews, tagging and assigning the SentiWordNet labels to each token of the corpus. \n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Part 4\n",
    "## 6.3\n",
    "\n",
    "The Senseval 2 Corpus contains data intended to train word-sense disambigua- tion classifiers. It contains data for four words: hard, interest, line, and serve. Choose one of these four words, and load the corresponding data:\n",
    "\n",
    "```python\n",
    "\n",
    "from nltk.corpus import senseval\n",
    "instances = senseval.instances('hard.pos')\n",
    "size = int(len(instances) * 0.1)\n",
    "train_set, test_set = instances[size:], instances[:size]\n",
    "```\n",
    "\n",
    "Using this dataset, build a classifier that predicts the correct sense tag for a given instance. See the corpus HOWTO at http://www.nltk.org/howto for information on using the instance objects returned by the Senseval 2 Corpus."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import senseval\n",
    "\n",
    "instances = senseval.instances('hard.pos')\n",
    "size = int(len(instances) * 0.1)\n",
    "train_set, test_set = instances[size:], instances[:size]\n",
    "\n",
    "def features(instance):\n",
    "    feat = dict()\n",
    "    p = instance.position\n",
    "       ## previous word and tag\n",
    "    if p: ## > 0\n",
    "        feat['wp'] = instance.context[p-1][0]\n",
    "        feat['tp'] = instance.context[p-1][1]\n",
    "       ## use BOS if it is the first word\n",
    "    else: # \n",
    "        feat['wp'] = (p, 'BOS')\n",
    "        feat['tp'] = (p, 'BOS')\n",
    "       ## following word and tag       \n",
    "        feat['wf'] = instance.context[p+1][0]\n",
    "        feat['tf'] = instance.context[p+1][1]\n",
    "    return feat\n",
    "\n",
    "featureset =[(features(i), i.senses[0]) for i in instances if len(i.senses)==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.944"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "from nltk import NaiveBayesClassifier, classify\n",
    "\n",
    "train, dev, test = featureset[500:], featureset[:250], featureset[250:500]\n",
    "classifier = NaiveBayesClassifier.train(train)\n",
    "classify.accuracy(classifier, dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "classify.accuracy(classifier, test)"
   ]
  }
 ]
}