{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.6 64-bit ('kadyrov': virtualenv)",
   "display_name": "Python 3.7.6 64-bit ('kadyrov': virtualenv)",
   "metadata": {
    "interpreter": {
     "hash": "939797fc98b4c25f5ce79e5f279b761a09ef165a500a9ca0016171b9b62055fd"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Daniel Kadyrov\n",
    "\n",
    "Stevens ID: 10455680\n",
    "\n",
    "CS557 - Natural Language Processing\n",
    "\n",
    "Group 32 - Daniel Kadyrov"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Part 1 \n",
    "\n",
    "Show your responses to the Your Turn practice of BKL Ch5 on pages 180. Try a variant of this exercise with the use of the two words “in” and “on”, as in “The book is not on the table, it is in my backpack”. Also tag the following sentence “Book the cooks who cook the books.” (a tagger based on the WSJ Corpus might be appropriate)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('like', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('swim', 'VB'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('swimming', 'NN'),\n",
       " ('pool', 'NN')]"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "import nltk \n",
    "\n",
    "text = \"I like to swim in the swimming pool\"\n",
    "text = nltk.word_tokenize(text)\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('book', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('not', 'RB'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('table', 'NN'),\n",
       " (',', ','),\n",
       " ('it', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('in', 'IN'),\n",
       " ('my', 'PRP$'),\n",
       " ('backpack', 'NN')]"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "text = \"The book is not on the table, it is in my backpack\"\n",
    "text = nltk.word_tokenize(text)\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('Book', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('cooks', 'NNS'),\n",
       " ('who', 'WP'),\n",
       " ('cook', 'VBP'),\n",
       " ('the', 'DT'),\n",
       " ('books', 'NNS')]"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "text = \"Book the cooks who cook the books\"\n",
    "text = nltk.word_tokenize(text)\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "source": [
    "# Part 2\n",
    "\n",
    "Respond to BKL Exercise 5.1 on p215. Tag the following sentence “Book the cooks who cook the books.” (a tagger based on the WSJ Corpus might be appropriate) and several other sentences you can think of with ambiguous words, as suggested by this exercise.\n",
    "\n",
    "## Exercise 5.1\n",
    "\n",
    "Search the Web for “spoof newspaper headlines,” to find such gems as: British Left Waffles on Falkland Islands, and Juvenile Court to Try Shooting Defendant. Manually tag these headlines to see whether knowledge of the part-of-speech tags removes the ambiguity."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('Juvenile', 'NNP'),\n",
       " ('Court', 'NNP'),\n",
       " ('to', 'TO'),\n",
       " ('Try', 'VB'),\n",
       " ('Shooting', 'NNP'),\n",
       " ('Defendant', 'NNP')]"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "headline = \"Juvenile Court to Try Shooting Defendant\"\n",
    "headline = nltk.word_tokenize(headline)\n",
    "nltk.pos_tag(headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('Book', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('cooks', 'NNS'),\n",
       " ('who', 'WP'),\n",
       " ('cook', 'VBP'),\n",
       " ('the', 'DT'),\n",
       " ('books', 'NNS')]"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "text = \"Book the cooks who cook the books\"\n",
    "text = nltk.word_tokenize(text)\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('Panda', 'NNP'),\n",
       " ('eats', 'VBZ'),\n",
       " ('shoots', 'NNS'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('leaves', 'NNS')]"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "text = \"Panda eats shoots, and leaves\"\n",
    "text = nltk.word_tokenize(text)\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('Panda', 'NNP'),\n",
       " ('eats', 'VBZ'),\n",
       " ('shoots', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('leaves', 'NNS')]"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "text = \"Panda eats shoots and leaves\"\n",
    "text = nltk.word_tokenize(text)\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('Include', 'NNP'),\n",
       " ('your', 'PRP$'),\n",
       " ('children', 'NNS'),\n",
       " ('when', 'WRB'),\n",
       " ('baking', 'VBG'),\n",
       " ('cookies', 'NNS')]"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "text = \"Include your children when baking cookies\"\n",
    "text = nltk.word_tokenize(text)\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "source": [
    "# Part 3 \n",
    "\n",
    "Respond to Exercise 12.10 from J&M 2rd Ch12 for at least one Wh- terminal. The lexicon and grammar in Figures 10.2 and 10.3 should be enough. If not indicate any other terminals and rules necessary.  Obviously the Wh- you chose needs to be a terminal. You are welcome to search the WWW for help here; be sure to show references to the sites you use."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Exercise 12.10\n",
    "\n",
    "Page 397 discussed the need for a Wh-NP constituent. The simplest Wh-NP is one of the Wh-pronouns (who, whom, whose, which). The Wh-words what and which can be determiners: which four will you have?, what credit do you have with the Duke? Write rules for the different types of Wh-NPs."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "WH-NP -> Wh-Pro\n",
    "\n",
    "WH-NP -> Wh-Det Nominal\n",
    "\n",
    "Wh-Pro -> who, whom, whose, which\n",
    "\n",
    "Wh-Det -> what, which"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Part 4 \n",
    "\n",
    "Chapter 10 of J&M 3rd and Chapter 5 of BKL demonstrate several taggers. Make a list of them and any others you can find with a brief statement as to what they do, what is distinctive about them, and what is like the other taggers in the chapter. You can show them with a table of at least 4 columns: ID, Description, Distinctive Feature(s), and “Similar To”. The Description should include words used in both J&M 2nd and 3rd and BKL, such as “bidirectional MEMM-style”, “regular expression tagger”, “lookup tagger”, etc. to distinguish the taggers."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "| ID                 | Description                                                                                                                                              | Distinctive Features | Similar To     |\n",
    "|--------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------|----------------|\n",
    "| Default Tagger     | POS Tagger                                                                                                                                               | POS, NLTK            | POS            |\n",
    "| POS Tagger         | Part of Speech\\. Processes a sequence of words and attaches a part of speech tag to each word                                                            | Speech Tag , NLTK    | POS            |\n",
    "| Regular Expression | Assigns tags to tokens based on matching patterns                                                                                                        | POS, NLTK            | POS            |\n",
    "| Lookup Tagger      | Initially uses a lookup table to assign tokens that the tagger identified as None\\. Then uses backoff, where one tagger acts as a parameter to another\\. | Regex, NLTK          | POS            |\n",
    "| Unigram Tagger     | Each token gets assign a tag that is most likely for that particular token                                                                               | POS, isolated word   | Lookup Tagger  |\n",
    "| N\\-Gram Tagger     | Uses n\\-1 preceding words to give context to the current word                                                                                            |                      | Unigram Tagger |\n",
    "| Brill Tagger       | Guesses the tag of each word, then goes back to fix the mistake                                                                                          | Supervised Learning  |                |\n",
    "| MEMM               | Maximum Entropy Markov Model\\. Uses logistic regression to classify words based on the words in its succession                                           |                      |                |\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Part 5 \n",
    "\n",
    "Tag the longest \"sentence\" you found from Assignment 2. Compare the results for at least two different taggers. Briefly discuss what applying embeddings to this might produce. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'On this subject it might become me better to be silent or to speak with diffidence; but as something may be expected, the occasion, I hope, will be admitted as an apology if I venture to say that if a preference, upon principle, of a free republican government, formed upon long and serious reflection, after a diligent and impartial inquiry after truth; if an attachment to the Constitution of the United States, and a conscientious determination to support it until it shall be altered by the judgments and wishes of the people, expressed in the mode prescribed in it; if a respectful attention to the constitutions of the individual States and a constant caution and delicacy toward the State governments; if an equal and impartial regard to the rights, interest, honor, and happiness of all the States in the Union, without preference or regard to a northern or southern, an eastern or western, position, their various political opinions on unessential points or their personal attachments; if a love of virtuous men of all parties and denominations; if a love of science and letters and a wish to patronize every rational effort to encourage schools, colleges, universities, academies, and every institution for propagating knowledge, virtue, and religion among all classes of the people, not only for their benign influence on the happiness of life in all its stages and classes, and of society in all its forms, but as the only means of preserving our Constitution from its natural enemies, the spirit of sophistry, the spirit of party, the spirit of intrigue, the profligacy of corruption, and the pestilence of foreign influence, which is the angel of destruction to elective governments; if a love of equal laws, of justice, and humanity in the interior administration; if an inclination to improve agriculture, commerce, and manufacturers for necessity, convenience, and defense; if a spirit of equity and humanity toward the aboriginal nations of America, and a disposition to meliorate their condition by inclining them to be more friendly to us, and our citizens to be more friendly to them; if an inflexible determination to maintain peace and inviolable faith with all nations, and that system of neutrality and impartiality among the belligerent powers of Europe which has been adopted by this Government and so solemnly sanctioned by both Houses of Congress and applauded by the legislatures of the States and the public opinion, until it shall be otherwise ordained by Congress; if a personal esteem for the French nation, formed in a residence of seven years chiefly among them, and a sincere desire to preserve the friendship which has been so much for the honor and interest of both nations; if, while the conscious honor and integrity of the people of America and the internal sentiment of their own power and energies must be preserved, an earnest endeavor to investigate every just cause and remove every colorable pretense of complaint; if an intention to pursue by amicable negotiation a reparation for the injuries that have been committed on the commerce of our fellow-citizens by whatever nation, and if success can not be obtained, to lay the facts before the Legislature, that they may consider what further measures the honor and interest of the Government and its constituents demand; if a resolution to do justice as far as may depend upon me, at all times and to all nations, and maintain peace, friendship, and benevolence with all the world; if an unshaken confidence in the honor, spirit, and resources of the American people, on which I have so often hazarded my all and never been deceived; if elevated ideas of the high destinies of this country and of my own duties toward it, founded on a knowledge of the moral principles and intellectual improvements of the people deeply engraven on my mind in early life, and not obscured but exalted by experience and age; and, with humble reverence, I feel it to be my duty to add, if a veneration for the religion of a people who profess and call themselves Christians, and a fixed resolution to consider a decent respect for Christianity among the best recommendations for the public service, can enable me in any degree to comply with your wishes, it shall be my strenuous endeavor that this sagacious injunction of the two Houses shall not be without effect.'"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "# From Assignment 2 \n",
    "from nltk.corpus import inaugural\n",
    "from nltk.tokenize import sent_tokenize \n",
    "\n",
    "sents = sent_tokenize(inaugural.raw())\n",
    "max_sent = max(sents, key=len)\n",
    "max_sent_toke = nltk.word_tokenize(max_sent)\n",
    "\n",
    "max_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('On', 'NN'),\n",
       " ('this', 'NNS'),\n",
       " ('subject', 'NN'),\n",
       " ('it', 'NN'),\n",
       " ('might', 'NN'),\n",
       " ('become', 'NN'),\n",
       " ('me', 'NN'),\n",
       " ('better', 'NN'),\n",
       " ('to', 'NN'),\n",
       " ('be', 'NN'),\n",
       " ('silent', 'NN'),\n",
       " ('or', 'NN'),\n",
       " ('to', 'NN'),\n",
       " ('speak', 'NN'),\n",
       " ('with', 'NN'),\n",
       " ('diffidence', 'NN'),\n",
       " (';', 'NN'),\n",
       " ('but', 'NN'),\n",
       " ('as', 'NNS'),\n",
       " ('something', 'VBG')]"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "\n",
    "# Regular Expression Tagger\n",
    "\n",
    "patterns = [\n",
    "    (r'.*ing$', 'VBG'), # gerunds\n",
    "    (r'.*ed$', 'VBD'), # simple past\n",
    "    (r'.*es$', 'VBZ'), # 3rd singular present\n",
    "    (r'.*ould$', 'MD'), # modals\n",
    "    (r'.*\\'s$', 'NN$'), # possessive nouns\n",
    "    (r'.*s$', 'NNS'), # plural nouns\n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'CD'), # cardinal numbers\n",
    "    (r'.*', 'NN') # nouns (default)\n",
    "]\n",
    "\n",
    "regexp_tagger = nltk.RegexpTagger(patterns)\n",
    "regexp_tagger.tag(max_sent_toke)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('On', 'IN'),\n",
       " ('this', 'DT'),\n",
       " ('subject', 'NN'),\n",
       " ('it', 'PPS'),\n",
       " ('might', 'MD'),\n",
       " ('become', 'VBN'),\n",
       " ('me', 'PPO'),\n",
       " ('better', 'JJR'),\n",
       " ('to', 'TO'),\n",
       " ('be', 'BE'),\n",
       " ('silent', 'JJ'),\n",
       " ('or', 'CC'),\n",
       " ('to', 'TO'),\n",
       " ('speak', 'VB'),\n",
       " ('with', 'IN'),\n",
       " ('diffidence', 'NN'),\n",
       " (';', '.'),\n",
       " ('but', 'CC'),\n",
       " ('as', 'CS'),\n",
       " ('something', 'PN')]"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "\n",
    "# Lookup Tagger\n",
    "\n",
    "fd = nltk.FreqDist(brown.words(categories=\"news\"))\n",
    "cfd = nltk.ConditionalFreqDist(brown.tagged_words(categories=\"news\"))\n",
    "\n",
    "most_freq_words = list(fd.keys())\n",
    "\n",
    "likely_tags = dict((word, cfd[word].max()) for word in most_freq_words)\n",
    "\n",
    "baseline_tagger = nltk.UnigramTagger(model=likely_tags, backoff=nltk.DefaultTagger(\"NN\"))\n",
    "\n",
    "baseline_tagger.tag(max_sent_toke[:20])"
   ]
  },
  {
   "source": [
    "The Lookup tagger tested performed better than the Regular Expression tagger at tagging the longest sentence of the inaugural address. As the regex patterns increase, this might be fixed but that requires predicting and identifying every possible pattern versus the lookup tagger learns as its baseline tagger and backoff memory increase. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}